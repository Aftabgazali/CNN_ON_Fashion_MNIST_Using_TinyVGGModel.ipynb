{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "aBb08o4CNSeV",
        "1YKpPEnsTs3g"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPrg1FWv1WQn9AVOdiNiSXJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aftabgazali/CNN_ON_Fashion_MNIST_Using_TinyVGGModel.ipynb/blob/main/CNN_ON_Fashion_MNIST_Using_TinyVGGModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Libraries"
      ],
      "metadata": {
        "id": "AqeiG53eM_kL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVMwF5uNM8Bx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Dataset & Preparing the Transform"
      ],
      "metadata": {
        "id": "aBb08o4CNSeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Because Fashion Mnist dataset is already in a gray scale form, hence we only need to convert the images into a Tensor data, Hence `ToTensor()`\n",
        "(check the shape of the image, we get 1,28,28 which is a gray scale image\n",
        "`image.shape`),"
      ],
      "metadata": {
        "id": "aL1fzvR-90Ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([ToTensor()])"
      ],
      "metadata": {
        "id": "c6YnnoxANWbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(root=\"data\", train = True, transform = transform, target_transform= None, download = True)\n",
        "test_data = datasets.FashionMNIST(root=\"data\", train= False, transform= transform, target_transform=None, download=True)"
      ],
      "metadata": {
        "id": "lHCxpJpANcyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "HysLdblbODrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "qdGFVN8jOHVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_ids = train_data.class_to_idx\n",
        "class_ids"
      ],
      "metadata": {
        "id": "qFkIzjLwOKp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Dataset"
      ],
      "metadata": {
        "id": "6KAPbc0sORB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = torch.randint(0, len(train_data), size=[1]).item()\n",
        "random_index"
      ],
      "metadata": {
        "id": "eQmDWl6POm2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10,7))\n",
        "\n",
        "rows,cols=4,4\n",
        "\n",
        "for i in range(1,rows*cols + 1):\n",
        "  random_index = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  image, label = train_data[random_index]\n",
        "  figure.add_subplot(rows,cols,i)\n",
        "  plt.imshow(image.squeeze())\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)\n"
      ],
      "metadata": {
        "id": "JvQXRzFJOS_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape of the image, we get 1,28,28 which is a gray scale image\n",
        "image.shape"
      ],
      "metadata": {
        "id": "xhk8Q7fJPDk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Data into Batches"
      ],
      "metadata": {
        "id": "BZwxcwpXPJi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_data, batch_size= BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "S3YqcYo0PNXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "tMy7ghxrPNgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the Images from Batches"
      ],
      "metadata": {
        "id": "hmxy_O-aPoc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_per_batchs, train_labels_per_batches = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "3zyrlx6XPNdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_features_per_batchs)"
      ],
      "metadata": {
        "id": "zMNcWCnRP2tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = torch.randint(0, len(train_features_per_batchs), size=[1]).item()\n",
        "\n",
        "random_index"
      ],
      "metadata": {
        "id": "ElJ2cOAmQfVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_per_batchs[random_index]"
      ],
      "metadata": {
        "id": "DM3LTU9CQi-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10,7))\n",
        "rows,cols = 4,4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_index = torch.randint(0, len(train_features_per_batchs), size = [1]).item()\n",
        "  image, label = train_features_per_batchs[random_index], train_labels_per_batches[random_index]\n",
        "  figure.add_subplot(rows,cols,i)\n",
        "  plt.imshow(image.squeeze())\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "h65CW1Zj_YVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10,7))\n",
        "rows, cols= 4,4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_index = torch.randint(0, len(train_features_per_batchs), size=[1]).item()\n",
        "  image, label = train_features_per_batchs[random_index], train_labels_per_batches[random_index]\n",
        "  figure.add_subplot(rows,cols,i)\n",
        "  plt.imshow(image.squeeze())\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "Klpk77f1P7Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building our Baseline Model"
      ],
      "metadata": {
        "id": "do5YHlJlPLfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline model\n",
        "class FashionMnistV0(nn.Module):\n",
        "  def __init__(self, in_features:int,\n",
        "               out_features:int,\n",
        "               hidden_units: int):\n",
        "    super().__init__()\n",
        "    self.layer_stacked = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=in_features, out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units, out_features=out_features)\n",
        "    )\n",
        "  def forward(self, x:torch.Tensor()):\n",
        "    return self.layer_stacked(x)\n",
        "\n",
        "\n",
        "# Create the instance of the baseline model\n",
        "baseline_model = FashionMnistV0(in_features=28*28,out_features=len(class_names), hidden_units=10).to(device)\n",
        "baseline_model"
      ],
      "metadata": {
        "id": "PDVDIBktR2MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model.state_dict()"
      ],
      "metadata": {
        "id": "4pwmGuYnS2nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Loss and Optimizer for our Baseline Model"
      ],
      "metadata": {
        "id": "vZgrrCCqTdIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = nn.CrossEntropyLoss()\n",
        "model_optimizer = torch.optim.Adam(params = baseline_model.parameters(), lr = 0.02)"
      ],
      "metadata": {
        "id": "d6o-REOyTgzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the accuracy function"
      ],
      "metadata": {
        "id": "1YKpPEnsTs3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_accuracy(y_true, y_predictions):\n",
        "  accuracy = torch.eq(y_true, y_predictions).sum().item()\n",
        "  return((accuracy/len(y_true))*100)"
      ],
      "metadata": {
        "id": "vlnBmoLfTzBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & Testing Loop"
      ],
      "metadata": {
        "id": "auLWrd3-UEJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "  \"\"\" Prints difference between start & end time. \"\"\"\n",
        "\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "jdDFK2LRX-wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs=3\n",
        "\n",
        "train_start_on_cpu = timer()\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-----------------\")\n",
        "  # Training Mode\n",
        "  train_loss = 0\n",
        "\n",
        "  for batch, (X,y) in enumerate(train_dataloader):\n",
        "    baseline_model.train()\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # Forward Pass\n",
        "    y_pred = baseline_model(X)\n",
        "\n",
        "    # Training Loss\n",
        "    loss = model_loss(y_pred,y)\n",
        "    train_loss+=loss\n",
        "\n",
        "    #Optimizer zero grad\n",
        "    model_optimizer.zero_grad()\n",
        "\n",
        "    # Backpropogation\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer step\n",
        "    model_optimizer.step()\n",
        "\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked Through {(batch * len(X))}/{len(train_dataloader.dataset)} samples\")\n",
        "  # Update the training loss, we have accumulated train_loss in one batch of a train_dataloader, hence the final loss must be the\n",
        "  # the average with the length of the train_dataloader per epoch.\n",
        "  train_loss /=len(train_dataloader)\n",
        "\n",
        "  # Testing Mode\n",
        "  test_loss, test_acc = 0,0\n",
        "  baseline_model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      # Forward Pass\n",
        "      test_pred = baseline_model(X)\n",
        "\n",
        "      # Testing Loss\n",
        "      test_loss += model_loss(test_pred, y)\n",
        "\n",
        "      # Testing acc\n",
        "      test_acc += model_accuracy(y, test_pred.argmax(dim=1))\n",
        "\n",
        "    # Update the Testing Loss & Accuracy\n",
        "    print(f\"Training Loss per Batch {train_loss:.2f} | Testing Loss per Batch {test_loss/len(test_dataloader):.2f} | Testing Accuracy per Batch {test_acc/len(test_dataloader):.2f}\")\n",
        "\n",
        "train_time_end_on_cpu = timer()\n",
        "\n",
        "total_train_time_baseline_model = print_train_time(start=train_start_on_cpu,\n",
        "                                                   end=train_time_end_on_cpu,\n",
        "                                                   device=str(next(baseline_model.parameters()).device))"
      ],
      "metadata": {
        "id": "d_F9sRlIUGxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_train_time_baseline_model"
      ],
      "metadata": {
        "id": "dcDVB5-_Exg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Model Evaluation Function"
      ],
      "metadata": {
        "id": "0wyxvYmxZaVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "def eval_model(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              model_loss: torch.nn.Module,\n",
        "              model_accuracy,\n",
        "              device: torch.device = device):\n",
        "  \"\"\" Returns a dictionary containing the results of model predicting on data_loader \"\"\"\n",
        "  loss, acc = 0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in tqdm(data_loader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      test_pred = model(X)\n",
        "      loss+= model_loss(test_pred, y)\n",
        "\n",
        "      acc+= model_accuracy(y, test_pred.argmax(dim=1))\n",
        "\n",
        "    # Scale loss & accuracy to find the average loss/ per batches as well as average accuracy per batches\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return {\"model_name\": model.__class__.__name__,\"model_loss\": loss.item(), \"model_acc\":acc}"
      ],
      "metadata": {
        "id": "ox_hPfmSYRr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If we get an error here stating that one or more parameter on cpu, that means our main baseline model is still on cpu use `.to(device)` to put it on gpu"
      ],
      "metadata": {
        "id": "ydeEf9zaHPP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model_results = eval_model(baseline_model, test_dataloader, model_loss, model_accuracy)\n",
        "baseline_model_results"
      ],
      "metadata": {
        "id": "4p97NcfkajlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Device Agnostic code"
      ],
      "metadata": {
        "id": "yKxYS9B2b3Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "device"
      ],
      "metadata": {
        "id": "2C0aFdKRb5pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Non Linear Model"
      ],
      "metadata": {
        "id": "qRNM1ELncks7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMnistV1(nn.Module):\n",
        "  def __init__(self, in_features:int,\n",
        "               out_features:int,\n",
        "               hidden_units: int):\n",
        "    super().__init__()\n",
        "    self.layer_stacked = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=in_features, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=hidden_units*2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units*2, out_features=out_features)\n",
        "    )\n",
        "  def forward(self, x:torch.Tensor()):\n",
        "    return self.layer_stacked(x)\n",
        "\n",
        "\n",
        "# Create the instance of the baseline model\n",
        "model_v1 = FashionMnistV1(in_features=28*28,out_features=len(class_names), hidden_units=10).to(device)\n",
        "model_v1"
      ],
      "metadata": {
        "id": "pb9gm1QxcngN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Loss & Optimizer function"
      ],
      "metadata": {
        "id": "r3wNCuJAdOk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = nn.CrossEntropyLoss() # measures how wrong our model is\n",
        "model_optimizer = torch.optim.Adam(params = model_v1.parameters(), lr = 0.02) # tries to update our model's parameters to reduce the loss"
      ],
      "metadata": {
        "id": "6khREs9ndTSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Training & Testing Loop Function"
      ],
      "metadata": {
        "id": "pmbnzOhCeY0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "                    data_loader:torch.utils.data.DataLoader,\n",
        "                    no_of_epochs: int,\n",
        "                    model_loss: torch.nn.Module,\n",
        "                    model_optimizer: torch.optim,\n",
        "                    model_accuracy,\n",
        "               device: torch.device = device):\n",
        "\n",
        "  torch.manual_seed(42)\n",
        "  epochs= no_of_epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n-----------------\")\n",
        "    # Training Mode\n",
        "    train_loss,train_acc = 0,0\n",
        "    model.train()\n",
        "    for batch, (X,y) in enumerate(data_loader):\n",
        "      # Put X & y on GPU\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      # Forward Pass\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # Training Loss\n",
        "      loss = model_loss(y_pred,y)\n",
        "      train_loss+=loss\n",
        "\n",
        "      train_acc+= model_accuracy(y, y_pred.argmax(dim=1))\n",
        "\n",
        "      #Optimizer zero grad\n",
        "      model_optimizer.zero_grad()\n",
        "\n",
        "      # Backpropogation\n",
        "      loss.backward()\n",
        "\n",
        "      # Optimizer step\n",
        "      model_optimizer.step()\n",
        "\n",
        "      if batch % 400 == 0:\n",
        "        print(f\"Looked Through {(batch * len(X))}/{len(data_loader.dataset)} samples\")\n",
        "    # Update the training loss\n",
        "    train_loss /=len(data_loader)\n",
        "    train_acc /=len(data_loader)\n",
        "    print(f\"Train Loss {train_loss:.2f} | Training Accuracy {train_acc:.2f}\")"
      ],
      "metadata": {
        "id": "HceihNMyec6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "def test_step(model: torch.nn.Module,\n",
        "                    data_loader:torch.utils.data.DataLoader,\n",
        "                    model_loss: torch.nn.Module,\n",
        "                    model_accuracy,\n",
        "              device: torch.device = device):\n",
        "  \"\"\" Performs a Testing loop step over the test data loader \"\"\"\n",
        "    # Testing Mode\n",
        "  test_loss, test_acc = 0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in tqdm(data_loader):\n",
        "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "      # Forward Pass\n",
        "      test_pred = model(X_test)\n",
        "\n",
        "      # Testing Loss\n",
        "      test_loss += model_loss(test_pred, y_test)\n",
        "\n",
        "      # Testing acc\n",
        "      test_acc += model_accuracy(y_test, test_pred.argmax(dim=1))\n",
        "\n",
        "    # Update the Testing Loss & Accuracy\n",
        "    print(f\"Testing Loss per Batch {test_loss/len(data_loader):.2f} | Testing Accuracy per Batch {test_acc/len(data_loader):.2f}\")"
      ],
      "metadata": {
        "id": "hb0-GQ0AuS7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(model_v1, train_dataloader, 3, model_loss, model_optimizer, model_accuracy, device)"
      ],
      "metadata": {
        "id": "b0EAROOIfly-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_step(model_v1, test_dataloader,model_loss, model_accuracy,device)"
      ],
      "metadata": {
        "id": "yciNU2wKwSWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v1_results = eval_model(model_v1, test_dataloader, model_loss, model_accuracy, device)\n",
        "model_v1_results"
      ],
      "metadata": {
        "id": "R8D4sbRpyq-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: V2 Building Convolutional Neural Networks\n",
        "\n",
        "***Note:*** For more insights visit https://poloclub.github.io/cnn-explainer/"
      ],
      "metadata": {
        "id": "GAt2TwUHzL7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an test image to pass through our model\n",
        "\n",
        "test_image = torch.randn(size=(1,28,28))"
      ],
      "metadata": {
        "id": "8jfNPs7x4CM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMnistV2(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture that replicates the TinyVGG, a model from the above polo link\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units:int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),# Values that we can set ourself, this are called as Hyper parameters\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2))# Output will be the divided by the kernel size(i.e. half) the size of input layer, what maxpool does is, in a kernel size of 2x2 on the input layer it takes the max value and assign it in place of the 2x2 matrix.\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),# Values that we can set ourself, this are called as Hyper parameters\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2))\n",
        "    self.classifier_layer = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7, out_features=output_shape) # Finding the units for last layer is a mystery\n",
        "    )\n",
        "\n",
        "  # Forward Pass Method\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    return self.classifier_layer(x)\n",
        "\n",
        "model_v2 = FashionMnistV2(input_shape=1,hidden_units=10, output_shape=len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "SRdF_kb2zOx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v2(test_image.unsqueeze(0).to(device))"
      ],
      "metadata": {
        "id": "hYAspS5d4EM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = nn.CrossEntropyLoss() # measures how wrong our model is\n",
        "model_optimizer = torch.optim.Adam(params = model_v2.parameters(), lr = 0.005) # tries to update our model's parameters to reduce the loss"
      ],
      "metadata": {
        "id": "iB131nsa5CPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Training & Testing Step"
      ],
      "metadata": {
        "id": "3TUHu4UW4wNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "def train_step(model:torch.nn.Module,\n",
        "               no_of_epochs: int,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               model_loss: torch.nn.Module,\n",
        "               model_acc,\n",
        "               model_optimizer: torch.optim,\n",
        "               device: torch.device = device):\n",
        "  for epoch in tqdm(range(no_of_epochs)):\n",
        "    print(f\"Epoch {epoch} ----------------------\")\n",
        "    # Training Mode\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0,0\n",
        "    for batch, (X,y) in enumerate(data_loader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      train_pred = model(X)\n",
        "\n",
        "      # Calculate the training loss\n",
        "      loss = model_loss(train_pred, y)\n",
        "      train_loss += loss\n",
        "\n",
        "      # Calculate the training acc\n",
        "      train_acc += model_acc(y, train_pred.argmax(dim=1))\n",
        "\n",
        "      # optimizer zero grad\n",
        "      model_optimizer.zero_grad()\n",
        "\n",
        "      # Loss Backward\n",
        "      loss.backward()\n",
        "\n",
        "      # Optimizer step\n",
        "      model_optimizer.step()\n",
        "\n",
        "      if batch % 400 == 0:\n",
        "        print(f\"Looked Through {batch * len(X)}/{len(data_loader.dataset)} samples\")\n",
        "\n",
        "    print(f\"Training Loss per batch {train_loss/len(data_loader)} Train Accuracy per batch {train_acc/len(data_loader)}\")"
      ],
      "metadata": {
        "id": "hqVSmB0z4xp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(model_v2, 3, train_dataloader, model_loss, model_accuracy, model_optimizer)"
      ],
      "metadata": {
        "id": "BVdd1WIq4zSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "def test_step(model:torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               model_loss: torch.nn.Module,\n",
        "               model_acc,\n",
        "               device: torch.device = device):\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_loss, test_acc = 0,0\n",
        "    for (X,y) in tqdm(data_loader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      test_pred = model(X)\n",
        "\n",
        "      # Calculate the training loss\n",
        "      loss = model_loss(test_pred, y)\n",
        "      test_loss += loss\n",
        "\n",
        "      # Calculate the training acc\n",
        "      test_acc += model_acc(y, test_pred.argmax(dim=1))\n",
        "\n",
        "    print(f\"Testing Loss per batch {test_loss/len(data_loader)} Test Accuracy per batch {test_acc/len(data_loader)}\")"
      ],
      "metadata": {
        "id": "Z7nd5neC40-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_step(model_v2, test_dataloader, model_loss, model_accuracy)"
      ],
      "metadata": {
        "id": "ne0aC02W42mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model_results = eval_model(baseline_model, test_dataloader, model_loss, model_accuracy)\n",
        "model_v1_results = eval_model(model_v1, test_dataloader, model_loss, model_accuracy)\n",
        "model_v2_results = eval_model(model_v2, test_dataloader, model_loss, model_accuracy)"
      ],
      "metadata": {
        "id": "m5XwQqN07qTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame([baseline_model_results, model_v1_results,model_v2_results])\n",
        "df"
      ],
      "metadata": {
        "id": "2rZuCBsP87Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
        "plt.xlabel(\"Accuracy %\")\n",
        "plt.ylabel(\"Models \")"
      ],
      "metadata": {
        "id": "vPo-dm4IArkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Predictions"
      ],
      "metadata": {
        "id": "doeyQvJV902y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_per_batch, test_labels_per_batch = next(iter(test_dataloader))"
      ],
      "metadata": {
        "id": "-HyD2L3L98km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = torch.randint(0, len(test_images_per_batch), size=[1]).item()\n",
        "random_index"
      ],
      "metadata": {
        "id": "1ntPuz8a90D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_per_batch[random_index].shape"
      ],
      "metadata": {
        "id": "NM57U3PD-6nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction = model_v2(test_images_per_batch[random_index].unsqueeze(0).to(device))\n",
        "test_prediction"
      ],
      "metadata": {
        "id": "qzQ_FJSd_U7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_images_per_batch[random_index].squeeze())"
      ],
      "metadata": {
        "id": "5gDQALI6_lbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_label = test_labels_per_batch[random_index]\n",
        "print(f\"Actual Image class name {class_names[test_label]} | Predicted Image class name is {class_names[test_prediction.argmax(dim=1)]}\")"
      ],
      "metadata": {
        "id": "A2EMZTXp-Jtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Even Better Visualization"
      ],
      "metadata": {
        "id": "iJY5Gi0vChjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10,7))\n",
        "rows,cols = 4,4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_index = torch.randint(0, len(test_images_per_batch), size = [1]).item()\n",
        "  image, label = test_images_per_batch[random_index], test_labels_per_batch[random_index]\n",
        "\n",
        "  # Make prediction, unsqueeze() to add the batch dimension which is required by the model\n",
        "  y_logits = model_v2(image.unsqueeze(0).to(device))\n",
        "  # From logits we pick the index value which has maximum activation value so here from 10(class) values we pick one index with maximum value\n",
        "  test_prediction_label = y_logits.argmax(dim=1)\n",
        "  figure.add_subplot(rows,cols,i)\n",
        "  plt.imshow(image.squeeze())\n",
        "  plt.title(class_names[test_prediction_label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "oHEnHK58BfPq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}